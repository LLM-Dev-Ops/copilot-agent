# Default values for llm-copilot-agent Helm chart
# This is a YAML-formatted file.

# Global settings
global:
  imagePullSecrets: []
  storageClass: ""

# Image configuration
image:
  repository: llm-copilot-agent
  pullPolicy: IfNotPresent
  tag: "latest"

# Service account configuration
serviceAccount:
  create: true
  annotations: {}
  name: "llm-copilot-sa"

# Deployment configuration
replicaCount: 3

# Update strategy
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"

# Pod labels
podLabels: {}

# Pod security context
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

# Container security context
securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL

# Service configuration
service:
  type: ClusterIP
  http:
    port: 80
    targetPort: 8080
  grpc:
    port: 50051
    targetPort: 50051
  metrics:
    port: 9090
    targetPort: 9090
  annotations: {}

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
  hosts:
    - host: copilot.example.com
      paths:
        - path: /api
          pathType: Prefix
    - host: api.copilot.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: llm-copilot-tls
      hosts:
        - copilot.example.com
        - api.copilot.example.com

# gRPC Ingress configuration
grpcIngress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: grpc.copilot.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: llm-copilot-tls
      hosts:
        - grpc.copilot.example.com

# Resource limits and requests
resources:
  limits:
    cpu: 2000m
    memory: 2Gi
    ephemeral-storage: 2Gi
  requests:
    cpu: 500m
    memory: 512Mi
    ephemeral-storage: 1Gi

# Horizontal Pod Autoscaler
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity and anti-affinity
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - llm-copilot-agent
        topologyKey: kubernetes.io/hostname

# Probes configuration
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 3
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  successThreshold: 1
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 0
  periodSeconds: 5
  timeoutSeconds: 3
  successThreshold: 1
  failureThreshold: 12

# Application configuration
config:
  # Logging
  logLevel: "info"
  rustBacktrace: "1"

  # Server
  httpPort: 8080
  grpcPort: 50051
  metricsPort: 9090
  workers: 4
  maxConnections: 1000

  # Feature flags
  enableMetrics: true
  enableTracing: true
  enableRateLimiting: true
  enableCaching: true
  enableDistributedTracing: true

  # LLM Provider
  llm:
    provider: "openai"
    model: "gpt-4"
    maxTokens: 4096
    temperature: 0.7
    timeout: 30

  # Agent
  agent:
    maxIterations: 10
    timeout: 300
    maxConcurrentTasks: 5

  # Rate Limiting
  rateLimit:
    requests: 100
    window: 60

  # CORS
  cors:
    allowedOrigins: "*"
    allowedMethods: "GET,POST,PUT,DELETE,OPTIONS"
    allowedHeaders: "Content-Type,Authorization"

# Database configuration
database:
  host: "postgres-service.llm-copilot.svc.cluster.local"
  port: 5432
  name: "copilot_db"
  username: "copilot"
  maxConnections: 20
  minConnections: 5
  timeout: 30

# Redis configuration
redis:
  host: "redis-service.llm-copilot.svc.cluster.local"
  port: 6379
  poolSize: 10
  timeout: 5

# NATS configuration
nats:
  host: "nats-service.llm-copilot.svc.cluster.local"
  port: 4222
  clusterName: "copilot-cluster"

# Secrets (set via --set or separate secrets file)
secrets:
  databasePassword: ""
  redisPassword: ""
  jwtSecret: ""
  openaiApiKey: ""
  anthropicApiKey: ""
  encryptionKey: ""

# Persistence
persistence:
  enabled: false
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 10Gi

# Monitoring
monitoring:
  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s

  prometheusRule:
    enabled: true
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"

      - alert: HighMemoryUsage
        expr: container_memory_usage_bytes{container="llm-copilot-agent"} / container_spec_memory_limit_bytes{container="llm-copilot-agent"} > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"

# Network Policy
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress

# Init containers
initContainers:
  waitForPostgres:
    enabled: true
    image: busybox:1.36
  waitForRedis:
    enabled: true
    image: busybox:1.36

# Extra volumes
extraVolumes: []

# Extra volume mounts
extraVolumeMounts: []

# Extra environment variables
extraEnv: []

# Extra containers
extraContainers: []

# PostgreSQL dependency (Bitnami chart)
postgresql:
  enabled: true
  auth:
    username: copilot
    password: copilot_password
    database: copilot_db
  primary:
    persistence:
      enabled: true
      size: 20Gi
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
      limits:
        cpu: 1000m
        memory: 1Gi

# Redis dependency (Bitnami chart)
redis:
  enabled: true
  auth:
    enabled: true
    password: redis_password
  master:
    persistence:
      enabled: true
      size: 10Gi
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi

# Prometheus dependency
prometheus:
  enabled: false

# Grafana dependency
grafana:
  enabled: false
